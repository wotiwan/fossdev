# Тестирование

Тестирование — это способ убедиться, что код делает то, что мы ожидаем от него. Существует ручное и автоматическое тестирование. При ручном тестировании человек выполняет шаги из инструкции и фиксирует поведение приложения или кода. При автоматическом тесты выполняются специальным инструментом, и собирается статистика пройденных или проваленных тестов. 
Зачем нужно ручное тестирование, когда автоматические тесты выглядят гораздо удобней — один раз написал и пользуйся? Ручные тесты с привлечением человека незаменимы, когда речь идет об апробации интерфейса. И в любых других задачах, когда сложно сформулировать критерии правильной работы. Здесь речь шла о готовом приложении, когда речь идет о коде, автоматическое тестирование незаменимо. Без автоматического тестирования невозможно было обеспечить [CI](https://www.atlassian.com/continuous-delivery/continuous-integration/how-to-get-to-continuous-integration) /[CD](https://aws.amazon.com/ru/devops/continuous-delivery/) (continuous integration/continuous delivery). CI/CD позволяют иметь оттестированную версию приложения в любой момент времени. 

## Мотивация

Существует несколько аргументов, что тесты — это не пустая трата времени:

1. Первая очевидная функция — это уменьшение вероятности возникновения ошибок в коде. Много мелких ошибок могут привести к серьезной проблеме, и тесты призваны предотвратить появление таких ошибок в коде. Существуют системы, которые будут автоматически проводить тестирование при загрузке кода в репозиторий, и это просто не даст разработчику залить не полностью рабочий код, но это возможно только при наличии автоматизированных тестов.

2. Этот пункт скорее психологический — у разработчика появляется инструмент, который подскажет ему, если он ошибся. Разработчик тратит меньше внимания на возможность возникновения ошибок, ведь у него есть система тестов, и соответственно больше внимания уделяет написанию кода, более смело экспериментирует, ведь тесты подскажут ему, если он сломал другой участок программы. Таким образом, тесты способствуют более быстрой работе и появлению более интересных решений.

3. Тесты можно рассматривать как своего рода документацию: то, как мы можем использовать функционал нашего приложения.
 
## Виды тестов

Выделяют несколько видов тестирования.

### Модульное тестирование

Модульное или unit-тестирование. Как видно из названия, мы тестируем отдельные модули, или «единицы» (участки) кода. Модульные тесты наиболее близки к контексту конкретных функций или других логически обособленных участков кода. Отсюда вытекает одно из основных свойств модульных тестов — изолированность: если мы тестируем функцию `foo`, то там не должно быть участков, связанных с функцией `bar`. Модульные тесты позволяют проверить отдельные части кода, прежде чем тестировать их совместно. 

![testing_types](/graphics/testing_types.png)

Модульное тестирование:
  * может помочь при разработке: понимая, что каждый участок кода нужно будет протестировать отдельно, разработчик с большей вероятностью не будет создавать большие функции со смешанной логикой, а разобьет ту же функциональность на несколько маленьких функций, каждую из которых будет понятно, как протестировать. Это, в конечном счете, положительно влияет на то, как выглядит API библиотеки.
  * заставляет задуматься о входных данных, которые подаются на вход коду, и лучше погрузиться в контекст решаемой задачи. 
  * позволяет протестировать часть кода, если в данный момент на другой частью работает другой человек, и она не проходит все тесты.
  * покрытие тестами всех возможных вариантов зависит от разработчика.
  * позволяет реализовывать подход «пиши код и тестируй одновременно». Так как модульные тесты атомарны по природе, мы можем выделять новые ситуации непосредственно во время написания кода и облачать их в тест.
  * позволяет другим разработчикам убедиться, что у них все настроено правильно и можно продолжать разработку. Если тесты не проходят, значит, нужно остановиться и донастроить рабочее окружение.

Преимущества наличия модульных тестов в коде могут быть неочевидны сначала, но проблемы, которые копятся из-за отсутствия или недостаточного количества тестов, постепенно будут копиться, и со временем мы перестанем писать новую функциональность, а будем только разбирать баги.

![no_test_cycle](/graphics/no_test_cycle.png)


#### Пример 

Рассмотрим функции, которые генерируют последовательность N первых чисел целиком и отдельно четные и нечетные.

```python
#content of series.py in my_math package
def get_series(n):
    return list(range(n))
    
def get_even_series(n):
    series = get_series(n)
    even_series = [i * 2 for i in series]
    return even_series

def get_odd_series(n):
    series = get_series(n)
    odd_series = [i * 2 + 1 for i in series]
    return odd_series
```

Мы видим, что функции `get_even_series()` и `get_odd_series()` используют другую функцию `get_series()`. Это нормально и хорошо, когда есть возможность переиспользовать код в другом месте. Мы выделяем его в отдельный блок. Но все три функции должны быть протестированы без учета внутреннего устройства функции.

```python
#content of test_series.py
import pytest

from my_math.series import (get_series,
                            get_even_series,
                            get_odd_series)

class TestSeries:
    def test_series(self):
        assert get_series(5) == [0, 1, 2, 3, 4]

    def test_even_series(self):
        assert get_even_series(5) == [0, 2, 4, 6, 8]

    def test_odd_series(self):
        assert get_odd_series(5) == [1, 3, 5, 7, 9]

    # test include the same code as in the function implementation
    def test_even_series_bad(self):
        n = 5
        even_series = [i * 2 for i in get_series(n)]
        assert get_even_series(n) == even_series
    
    # test include several functions that can be tested separetely
    def test_all_series_bad(self):
        n = 5
        assert get_series(n) == [0, 1, 2, 3, 4]
        assert get_even_series(n) == [0, 2, 4, 6, 8]
        assert get_odd_series(n) == [1, 3, 5, 7, 9]
        
    # might be a good test
    def test_series_full(self):
        series = get_even_series(5) + get_odd_series(5)
        series.sort()
        assert get_series(10) == series
```

Давайте разберемся, что мы здесь видим. Тесты `test_series`, `test_even_series`, `test_odd_series` тестируют отдельно функциональность трех разных функций, поэтому это нормальные юнит-тесты. Мы можем написать генератор данных вместо использования фиксированных списков `[0, 1, 2, 3, 4]` и таким образом увеличить покрытие тестами. Мы вернемся к этому чуть позже, сейчас посмотрим на другие тесты. Тест `test_even_series_bad` не является хорошим тестом, так как мы используем ту же логику, что и при реализации функции, и если этот код будет немного сложнее, чем генерация списка чисел, то мы можем унести ошибку в тест, и он будет пройден, хотя функция работает не так, как закладывалось. Например, если нужно было генерировать числа, начиная с нуля, а мы генерируем с 1 `range(n) -> range(1, n)`. Тогда `test_series_should_fail_but_passed()` ниже не вызовет ошибок, так как мы просто скопировали код из функции. Тест `test_series` не пройдет, так как здесь данные сгенерированы независимо, и так мы поймем, что сделали ошибку:

```python
#content of series.py in my_math package
def get_series(n):
    return list(range(1, n))                        # we made mistake 

#content of test_series.py
import pytest

from my_math.series import (get_series)

class TestSeries:
    def test_series(self):
        assert get_series(5) == [0, 1, 2, 3, 4]

    def test_series_should_fail_but_passed(self):
        assert get_series(5) == list(range(1, n))   # and propagate it here
```

Посмотрим на тест `test_series_full`. Он включает в себя вызов нескольких функций, это может быть хорошей идеей, так как мы проверяем полноту данных. Такой тест не должен подменять собой другие тесты, где мы тестируем отдельные функции, но может дополнять их. Тест не настолько объемный, чтобы считаться **интеграционным тестом**, хотя он и объединяет несколько отдельных участков кода и говорит, как они должны работать совместно.

#### Параметризация тестов

В тестах выше мы использовали заранее определенные списки, которые были захардкожены прямо в тесте. Мы можем расширить функциональность тестов, используя [параметризацию](https://docs.pytest.org/en/7.1.x/example/parametrize.html) тестов. Добавим в `test_series.py` тесты, которые принимают параметр: 

```python
import pytest

from my_math.series import (get_series,
                            get_even_series,
                            get_odd_series)

class TestSeries:
    def test_series_parametrized(self, max_number):
        i = 0
        series = list()
        while i < max_number: 
            series.append(i)
            i = i + 1
        assert get_series(max_number) == series
```

И если мы попытаемся выполнить тесты, получим ошибку:

```bash
      def test_series_parametrized(self, max_number):
E       fixture 'max_number' not found
```

Мы видим новый термин `fixture`. В самом деле, непонятно, откуда pytest должен узнать, что подставить вместо `max_number` при автоматическом тестировании. Если добавить max_number значение по умолчанию, то ошибки не будет, но это не то, что мы хотим сделать. Значения `max_number` должны быть каким-то образом определены, и в pytest для этого используются `fixture`, которые хранят данные, используемые в тестах. Мы определяем `fixture` в файле `conftest.py`, и они будут доступны всем тестами. Эти данные определяются в отдельном файле, так как вызов функции отличается от вызовов тестов, и определение входных данных для тестов можно отнести к конфигурированию тестов `conftest -> configure test`. Добавим в `conftest` следующие строки:

```python
import pytest 

@pytest.fixture
def max_number():
    return 5
```

Теперь проходят все тесты. Посмотрим, как можно сделать вызов теста с разными параметрами. Заменим с: 

```python 
def pytest_generate_tests(metafunc):
    if "max_number" in metafunc.fixturenames:
        # end can be retrived from command line parameters
        end = 10    
        metafunc.parametrize("max_number", range(end))
```

Имя параметра, который мы хотим менять, — `max_number`, а `range(end)` задает диапазон значений. Здесь на первый взгляд происходит небольшая магия, но это то, как работает pytest с параметризованными тестами, и такие конструкции мы просто берем из документации. Функция `pytest_generate_tests` вызовется для каждого теста, далее мы посмотрим, что среди параметров-fixture есть тот, который нам нужен, и с помощью  `metafunc.parametrize()` сделаем из одного теста несколько, подставляя вместо одного значения диапазон значений `range(end)`. Значение `end` на текущий момент задано жестко, но может управляться при [запуске тестов](https://docs.pytest.org/en/7.1.x/example/simple.html#dynamically-adding-command-line-options). 

**Модульное тестирование позволяет понять, как части кода работают сами по себе**

## Интеграционное тестирование

Чтобы сделать интеграционное тестирование, нужно написать такие тесты, когда различные блоки, модули или компоненты программного приложения тестируются вместе. Интеграционное тестирование нужно для того, чтобы проверить ситуации, которые могут ускользнуть при юнит-тестировании. Основное отличие интеграционного теста от юнит-теста в том, что инициализируются все компоненты системы. Для юнит-теста мы можем определить тестовые данные непосредственно в тесте или через `fixture`. Для интеграционного теста мы положим такие же данные в базу данных и затем возьмем оттуда. Для интеграционного тестирования могут применяться как те же инструменты, что и для модульного тестирования, например, pytest, так и специальные инструменты, которые протестируют приложение с внешней стороны. Например, подадут тестовый запрос так, как бы это делал пользователь, что можно сделать с помощью [Selenium](https://www.techtarget.com/searchsoftwarequality/tip/Cypress-vs-Selenium-Compare-test-automation-frameworks). Подробнее про тестирование можно прочитать [здесь](https://www.techtarget.com/searchsoftwarequality/definition/integration-testing) или [здесь](https://docs.pylonsproject.org/projects/pyramid/en/latest/narr/testing.html).

**Интеграционное тестирование позволяет понять, как части кода и целые модули работают в контексте всей системы**

## Больше тестов 

Существует также системное тестирование, на этапе которого проверяется не только правильная функциональность частей системы, но и такие аспекты, как: 

  * [работа под нагрузкой](https://www.guru99.com/load-testing-tutorial.html).
  * [удобство использования](https://www.guru99.com/usability-testing-tutorial.html).
  * [обеспечение совместимости](https://www.guru99.com/regression-testing.html) с предыдущими версиями кода. Это не совсем то же самое, что прохождение юнит-тестов, здесь мы тестируем, что новая версия программы работает с данными так же, как старые. Даже с учетом того, что юнит-тесты не принято менять в процессе добавления новой функциональности.
  * [восстановление](https://www.guru99.com/recovery-testing.html) работы системы при авариях.
  * [миграционное](https://www.winwire.com/blog/data-migration-testing/) тестирование, при котором мы тестируем «переезд» на другие инструменты.

В этой главе мы не будем подробно останавливаться на этих тестах, так как это делается не только силами разработчиков, для целей данного курса мы подробно остановились на модульном тестировании. 

## Разработка через тестирование

TDD — test-driven development, разработка через тестирование. Выше мы сначала писали функциональность и затем придумывали тесты. В подходе TDD мы сначала пишем тесты и затем делаем так, чтобы разработанная нами функциональность проходила все тесты. Для разработки через тестирование требуется создать автоматизированные модульные тесты, как мы делали выше с помощью `pytest`, которые определяют требования к коду непосредственно перед написанием самого кода. Тест содержит проверки условий, которые могут либо выполняться, либо нет. Такие условия начинаются с ключевого слова `assert` в примерах выше. Когда они выполняются, говорят, что тест пройден. Прохождение теста подтверждает поведение, которые программист предполагает правильным. 

Цикл разработки через тестирование (на основе книги Кента Бека «Разработка через тестирование: на примере»):

  * **Добавление теста**. Добавление каждой новой функциональности начинается с написания теста. Только что написанный тест не будет проходить проверку, потому что код, который он тестирует, еще не написан (да, именно так). Если этот тест прошел проверку до написания кода, то данная функциональность уже реализована, либо же тест работает неправильно. Для написания теста разработчик должен четко понимать требования к новой функциональности — это и отличает TDD-подход от остальных, разработчик фокусируется на требованиях до написания кода.
  * **Запускаем все тесты, убеждаемся, что они не прошли**. На этом этапе мы проверяем сами тесты. Если написанный тест проходит всегда — значит, он бесполезен. Это увеличивает уверенность, хотя не гарантирует, что тест действительно тестирует то, что нам нужно.
  * **Пишем код**. На этом этапе пишем код так, чтобы он проходил тесты. Этот код не обязан быть идеальным. Код может быть некрасивым, это мы поправим на следующих этапах.  Главное, чтобы код был предназначен для прохождения этого теста. Не следует добавлять лишнюю функциональность, для которой не написан тест.
  * **Запускаем тесты, убеждаемся, что они проходят**. Если тесты прошли — программист может быть уверен, что код удовлетворяет всем требованиям, определенным на этапе добавления теста, но не более. Если нет — переписываем код и повторно прогоняем тесты до тех пор, пока тесты не будут выполнены.
  * **Рефакторинг**. Теперь настало время привести код в порядок. Это процесс изменения внутренней структуры программы, не затрагивающий ее внешнее поведение и имеющий целью облегчить понимание ее работы, устранить дублирование кода, облегчить внесение изменений, в общем, улучшить поддерживаемость кода. 
  * **Повторить цикл**. Повторяем описанный цикл и реализуем все новую и новую функциональность. Если вы используете сторонние библиотеки, не следует делать небольшие изменения, которые тестируют только функциональность библиотеки, а не ваш код, который использует ее. Исключением может быть случай, когда у вас есть подозрения, что сторонняя библиотека содержит ошибки. 

Разработка через тестирование позволяет сделать код чище и яснее, потому что мы пишем только те фрагменты, которые необходимы для прохождения тестирования. Также разработка тестов до написания программы позволяет писать код, который более пригоден для тестирования, что не скажешь о создании тестов после написания кода, когда бывает тяжело отделить одну функциональность от другой. TDD способствует тому, что тестами будет покрыта вся функциональность. 

### Пример 

Для демонстрации разработки тестирования мы будем писать класс «дробь» (`Fraction`). Назовем наш пакет fraction. В каталоге `fraction` создаем модуль `fraction.py`. В этом файле мы будем реализовывать функциональность нашего класса. Далее в корневой директории проекта создаем каталог `tests` и в нем файл `test_fraction.py`. Не забудьте добавить `__init__.py` в каталоги `tests` и `fraction`, чтобы они воспринимались как пакеты.  Пропишем в начале файла `import pytest`. Мы будем использовать библиотеку `pytest` для написания и выполнения тестов. Если на вашем рабочем окружении не установлен `pytest`, установите его:

```bash
pip install pytest. 
```

Структура файлов должна выглядеть так:

```
my_project
├── fraction
│   ├── __init__.py
│   └── fraction.py
└── tests
    ├── __init__.py
    └── test_fraction.py
```

В файле `test_fraction.py` мы будем писать тесты. Создадим класс `TestFraction`, в котором будем все писать. Для начала напишем код, который будет проверять корректность создания дроби. Для этого надо подумать, что наш класс будет принимать на вход. Пусть это будет числитель, `numerator`, и знаменатель, `denominator`. Все функции, которые что-либо тестируют в pytest, должны начинаться со слова *test*. Создадим функцию `test_fraction_creation()`, которая будет тестировать создание экземпляров Fraction. Давайте возьмем такие пары числитель-знаменатель: (5, 2), (6, 8), (-5, 2), (2, -5), (0, 1), (1, 0), (1, 1). Во время подготовки данных помним про опасность дробей, которые в знаменателе содержат ноль. В результате у нас должен получиться такой код:

```python
import pytest
from fraction.fraction import Fraction

class TestFraction:
   def test_fraction_creation(self):
       Fraction(5, 2)
       Fraction(6, 8)
       Fraction(-5, 2)
       Fraction(2, -5)
       Fraction(0, 1)
       Fraction(1, 0)
       Fraction(1, 1)
```

Теперь можем запустить тесты:

```bash
cd my_project
pytest
```

Мы запустили тесты! В отчете нам пишут, что:


```sh
ImportError: cannot import name 'Fraction' from 'fraction'.
```  

Наша программа не может найти класс Fraction. Для этого в файле fraction/__init__.py пропишем следующее: 

```python
from .fraction import Fraction
```

А в fraction/fraction.py создадим заготовку кода:

```python
class Fraction:
   def __init__(self, numerator, denominator):
       self.numerator = numerator
       self.denominator = denominator

```

Запускаем тесты — теперь у нас все работает:

```sh
============================== test session starts ===============================
platform linux -- Python 3.7.4, pytest-5.2.1, py-1.8.0, pluggy-0.13.0
rootdir: /home/artem/swdev/gitrepo/edu/toolchain/23_testing/code/fraction
plugins: doctestplus-0.4.0, arraydiff-0.3, remotedata-0.3.2, openfiles-0.4.0
collected 1 item                                                                 

tests/test_fraction.py .                                                   [100%]

=============================== 1 passed in 0.02s ================================

```

